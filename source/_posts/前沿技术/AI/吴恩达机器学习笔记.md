---
title: 吴恩达机器学习笔记
date: 2023年9月13日15:03:46
tags: 
    - 机器学习
    - AI
categories: 前沿技术
keywords:
description:
top_img: https://i1.hdslb.com/bfs/archive/f9edf6ac25cac9a4d796d7f6b3c947dd43fda90b.png@672w_378h_1c_!web-search-common-cover.avifhttps://i0.hdslb.com/bfs/archive/73ce549a9b791241679533da1af72dad1ec8ed90.jpg@672w_378h_1c_!web-search-common-cover.avif
comments:
cover: https://i0.hdslb.com/bfs/archive/73ce549a9b791241679533da1af72dad1ec8ed90.jpg@672w_378h_1c_!web-search-common-cover.avif
toc:
toc_number:
toc_style_simple:
copyright:
copyright_author:
copyright_author_href:
copyright_url:
copyright_info:
mathjax:
katex:
aplayer:
highlight_shrink:
aside:


---

<meta name="referrer" content="no-referrer"/>

# 一、 引言（Introduction）

## 1.1 什么是机器学习？

​		第一个机器学习的定义来自于**Arthur Samuel**。他定义机器学习为，在进行特定编程的情况下，给予计算机学习能力的领域。**Samuel**的定义可以回溯到50年代，他编写了一个西洋棋程序。这程序神奇之处在于，编程者自己并不是个下棋高手。但因为他太菜了，于是就通过编程，让西洋棋程序自己跟自己下了上万盘棋。通过观察哪种布局（棋盘位置）会赢，哪种布局会输，久而久之，这西洋棋程序明白了什么是好的布局，什么样是坏的布局。然后就牛逼大发了，程序通过学习后，玩西洋棋的水平超过了**Samuel**。这绝对是令人注目的成果。

## 1.2 监督学习

监督学习（supervised learning）指的就是我们给学习算法一个数据集，这个数据集含有“正确答案”的标签，机器通过学习输入数据到标签的映射，可预测接下来输入的无标签数据。

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230913151635791.png" alt="image-20230913151635791" style="zoom:67%;" />

上图很好地展示了监督学习过程，通过学习输入 X 和所需输出标签 Y 的数据对实现数据预测，即：“从正确答案中学习”，现实中机器学习的大部分的使用场景都是监督学习，如下图所示：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230913151829672.png" alt="image-20230913151829672" style="zoom:67%;" />

**Email**客户端中，你点击“垃圾邮件”按钮，报告某些**Email**为垃圾邮件，不会影响别的邮件。基于被标记为垃圾的邮件，您的电子邮件程序能更好地学习如何过滤垃圾邮件；输入音频文件及其对应的音频文本，机器即可学习如何将语音转化为文本。**总结来看，监督学习就是通过大量已经得知映射关系的数据集中，寻找映射逻辑并学习的过程。**

监督学习可以分为两种，分别是回归问题（Regression）与分类问题（Classification）。

![image-20230913153848528](https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230913153848528.png)

### 回归问题

假如你现在收集到关于房价与房屋面积的数据，你把这些数据画出来，看起来是这个样子：横轴表示房子的面积，单位是平方英尺，纵轴表示房价，单位是千美元。那基于这组数据，假如你有一个朋友，他有一套750平方英尺房子，现在他希望把房子卖掉，他想知道这房子能卖多少钱。

那么关于这个问题，机器学习算法将会怎么帮助你呢？

![img](https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/2d99281dfc992452c9d32e022ce71161.png)

应用学习算法拟合一条直线，根据这条线我们可以推测出这套房子可能卖多少钱。也可能还有更好的，比如我们不用直线拟合这些数据，用二次方程去拟合可能效果会更好。根据二次方程的曲线，我们可以从这个点推测出，这套房子能卖接近。这些都是学习算法里面很好的例子。

可以看出，监督学习指的就是我们给学习算法一个数据集。这个数据集由“正确答案”组成。在房价的例子中，我们给了一系列房子的数据，我们给定数据集中每个样本的正确价格，即它们实际的售价然后运用学习算法，算出更多的正确答案。比如你朋友那个新房子的价格。用术语来讲，这叫做**回归问题**。我们试着推测出一个连续值的结果，即房子的价格。

> **回归问题**：在监督学习中，我们给学习算法一个数据集，比如一系列房子的数据，给定数据集中每个样本的正确价格，即它们实际的售价然后运用学习算法，算出更多的答案，我们需要估算一个<font color='red'>连续值</font>的结果，这属于回归问题

### 分类问题

假设现在需要构建机器学习模型， 现在有这样的数据集：横轴表示乳腺癌肿瘤的大小，纵轴1代表乳腺癌恶性，0代表乳腺癌良性，如下图所示：

![image-20230913153252377](https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230913153252377.png)

或者是给定的数据集有超过两种变量输入，学习算法必须决定如何通过这些数据来模拟一条合适的边界线帮助医生诊断。

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230913153602338.png" alt="image-20230913153602338" style="zoom:67%;" />

机器学习的问题就在于，估算出肿瘤是恶性的或是良性的概率，属于**分类问题**。 

> **分类问题**：指的是我们试着推测出<font color='red'>离散</font>的输出值：0或1良性或恶性，而事实上在分类问题中，输出可能不止两个值。 

## 1.3 无监督学习

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230913154044869.png" alt="image-20230913154044869" style="zoom: 50%;" />

相较于监督学习，无监督学习的数据集没有任何的标签，不知道数据点是什么，也不知道如何处理。无监督学习算法可能会把这些数据分成多个不同的**簇**，叫做**聚类算法**。

![image-20230913154656788](https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230913154656788.png)

互联网上每天都有无数条新闻，如何将这么多的新闻分组组成关联的新闻就成为了聚类算法需要解决的问题，例如Google新闻中关于一个专题的报道，该报道的标题可以看出相近词使用频率很高，因此聚类算法将其划分为一类。

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230913155103251.png" alt="image-20230913155103251"  />

又例如人的DNA序列，通过输入很多人的某段DNA序列（一列代表一个人），聚类算法可以将DNA序列划分为多种类型或是不同的组。

关于无监督学习，没有提前告知算法一些信息，比如，这是第一类的人，那些是第二类的人，还有第三类，等等。我们只是告诉机器这是有一堆数据，我不知道数据里面有什么，我不知道谁是什么类型，我甚至不知道人们有哪些不同的类型，这些类型又是什么。但你能自动地找到数据中的结构吗？要机器自动地聚类那些个体到各个类，我没法提前知道哪些是哪些。因为我们没有给算法正确答案来回应数据集中的数据，所以这就是无监督学习。

 **应用**

- 基因学的理解应用
- 社交网络分析
- 组织大型计算机集群
- 细分市场
- 新闻事件分类

# 二、单变量线性回归(Linear Regression with One Variable)

## 2.1 模型表示

刚刚介绍了监督学习中的回归问题，单变量线性回归问题指的是将学习过程中控制机器学习的数据集只有一个自变量。有如下这样一个训练集，特征为房子的大小，因变量是房价。那么对于一个新的房子的大小，我们如何根据历史的数据来预测出来该房子的价格呢？

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230913202412591.png" alt="image-20230913202412591" style="zoom:67%;" />

可以看出，单变量线性回归模型中，模型是一条直线，通过输入房子大小根据得到的模型即可推断出该房子的售价。现在我们将训练集（Training Set）用下面表格的方式展示：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230913202747055.png" alt="image-20230913202747055" style="zoom:50%;" />

一些标注如下：

$m $代表训练集中实例的数量

$x$ 代表特征或者输入变量

$y$ 代表目标变量或者输出变量

$(x,y)$ 代表训练集中的实例

$(x^i,y^i)$ 代表第 $i$ 个观察实例

$h$ 代表学习算法的解决方案或函数(function)也称为假设（**hypothesis**）、模型（Model）

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230913211442052.png" alt="image-20230913211442052" style="zoom:50%;" />

上述就是一个监督学习算法的工作方式，将训练集（training set）投喂给机器学习算法后得到模型 f ，通过输入特征 x 到模型中，模型就可以预测可能得目标值 <img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230913213149751.png" alt="image-20230913213149751" style="zoom: 50%;" /> （读作 y hat)，需要区别 y 与 y hat，y 通常指代训练集中的目标变量，而y hat指代预测的目标变量。

一种可能的表达方式为：$h_{\theta}(x) = \theta_0 + \theta_1x$，因为只含有一个特征/输入变量，因此这样的问题叫作单变量线性回归问题。

## 2.2 代价函数

![image-20230913213711862](https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230913213711862.png)

假设有上述的训练集，$m$ 代表了训练集中实例的数量，例如$m = 47$，对样本进行线性回归预测，可以得到这样的线性函数：$f_{w,b} = wx + b$

$w$ 与 $b$ 可以称作参数（Parameters）或是权重（Weights），即线性函数的斜率与在y轴上的截距。$w$ 与 $b$ 参数值的选择决定了预测的精确度，不同的权重产生不同的模型，模型对于预测精确程度的判定标准称作**代价函数**。

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230913214148823.png" alt="image-20230913214148823" style="zoom:50%;" />

$y_{hat} ^{i} - y_i$ 的值称作**建模误差**（modeling error），不同的模型对于代价函数的选择可能不同，但是在单变量线性回归预测中最常使用的代价函数是平方差代价函数：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230913214448235.png" alt="image-20230913214448235" style="zoom:50%;" />

也可以写作：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230913215400114.png" alt="image-20230913215400114" style="zoom: 50%;" />

显然为了找到预测最精确的模型，需要模型参数带入到代价函数能使其$J(w,b)$值最小，即$minimizeJ(w,b)$

## 2.3 代价函数的直观理解

绘制一个等高线图，三个坐标分别为$w$和$b$ 和 $J(w,b)$：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230913220154623.png" alt="image-20230913220154623" style="zoom:67%;" />

则可以看出在三维空间中存在一个使得代价函数最小的点。另一种形式是等高线图，在取到代价最低点的参数时，模型预测准确度最高 。

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230913225228044.png" alt="image-20230913225228044" style="zoom:67%;" />

通过这些图形，我希望你能更好地理解这些代价函数所表达的值是什么样的，它们对应的假设是什么样的，以及什么样的假设对应的点，更接近于代价函数$J$的最小值。

## 2.4 梯度下降

梯度下降是一个用来求函数最小值的算法，我们将使用梯度下降算法来求出代价函数$J(w,b)$ 的最小值。

梯度下降背后思想：随机选择一个参数组合$(w_1,b_1)$，计算代价函数，然后我们寻找下一个能让代价函数值$J(w,b)$**下降最多**的参数组合，循环往复最终可以得到一个**局部最小值（local minimum）**，选择不同的初始参数组合，可能会找到不同的局部最小值。

![image-20230914120810107](https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230914120810107.png)

想象自己站在一座山的一点，在剃度下降算法中，我们需要旋转360度看看周围，根据判断选择下降最快的方向迈出一小步，随后再次旋转360度看看周围，再选择一次方向再迈出一小步。重复上述操作最终就会到达局部最低点的位置。

批量梯度下降（**batch gradient descent**）算法的公式为：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230914121113026.png" alt="image-20230914121113026" style="zoom:67%;" />

其中$\alpha$称作学习率（**learning rate**），它决定了我们沿着能让代价函数下降程度最大的方向向下迈出的步子有多大，在批量梯度下降中，我们每一次都同时让所有的参数减去学习速率乘以代价函数的导数，流程可以简述为：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230914121230185.png" alt="image-20230914121230185" style="zoom: 50%;" />

> 注意：$w$与$b$的更新是同步的，也就是说需要中间变量$tmp_w$与$tmp_b$存储运算结果。
>

## 2.5 梯度下降的直观理解

对于梯度下降算法的理解，不妨将二元函数$J(w,b)$的$b$参数值固定，假设其为0，那么对于$w$参数的梯度下降算法公式为：$w = w-\alpha\frac{\partial}{\partial w}J(w)$，函数图为下面的形式：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230914122530053.png" alt="image-20230914122530053" style="zoom:33%;" />

对于$\frac{\partial}{\partial w}J(w)$ 即在某一点$w = w_0$处的斜率，$\alpha$ 的取指大于 0，因此可以分为下面两种情况讨论：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230914122814808.png" alt="image-20230914122814808" style="zoom:67%;" />

1. $w_0$点位于局部最低点右侧，此时$\frac{\partial}{\partial w}J(w_0)$的值大于0，因此根据梯度下降算法$w = w-\alpha\frac{\partial}{\partial w}J(w)$ ,有$w_新 <w_0$。
2. 同理如果$w_0$点位于局部最低点左侧，$\frac{\partial}{\partial w}J(w_0)$的值小于0，$w_新 >w_0$

## 2.6 学习率$\alpha$

梯度下降算法$w = w-\alpha\frac{\partial}{\partial w}J(w)$中,学习率$\alpha$即下降中每一次下降的步长，下面讨论如果$\alpha$太大或是太小会出现什么情况：

- 如果$\alpha$太大：

梯度下降法可能会越过最低点，甚至可能无法收敛，下一次迭代又移动了一大步，越过一次，又越过一次，一次次越过最低点，直到你发现实际上离最低点越来越远，所以，如果太大，它会导致无法收敛，甚至发散。

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230914124310650.png" alt="image-20230914124310650" style="zoom: 50%;" />

- 如果$\alpha$太小：

如果太小了，即我的学习速率太小，结果就是只能这样像小宝宝一样一点点地挪动，去努力接近最低点，这样就需要很多步才能到达最低点。

对于另一种情况，如果说$（w_0，b_0）$ 初始化就在最低点，那么此时该点的偏导均为零，梯度下降算法的更新不会改变任何参数的值，来看下面这个例子：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230914124712149.png" alt="image-20230914124712149" style="zoom:67%;" />

越靠近局部最低点时，该点的偏导数就越小，直到取到局部最低点时偏导数为 0 ，也就是说：$w$与$b$参数偏移幅度在每一次偏移后都会缩小，直到偏移幅度缩小为零。

## 2.7 梯度下降的线性回归

如果将梯度下降函数中的偏导数求出来，即梯度下降函数可以转换为下面形式：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230914125307454.png" alt="image-20230914125307454" style="zoom:50%;" />

推倒过程如下：

![image-20230914125555039](https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230914125555039.png)

则算法改写为：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230914125514822.png" alt="image-20230914125514822" style="zoom:67%;" />

## 2.8 实训：训练单变量线性回归模型

[实训资料网站](https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes/tree/master/code/ex1-linear%20regression)

### 数据读取

数据集为`ex1data.txt`，数据形式如下：

```txt
6.1101,17.592
5.5277,9.1302
8.5186,13.662
7.0032,11.854
5.8598,6.8233
8.3829,11.886
7.4764,4.3483
    ...
8.2934,0.14454
13.394,9.0551
5.4369,0.61705
```

使用`read_csv()`读取文本中的数据：

```py
# 读取数据
path = 'ex1data1.txt'
data = pd.read_csv(path, header=None, names=['Population', 'Profit']
```

### 数据提取

读取数据总行数为：97，data目前可以看做一个(97,2)的矩阵，第一列为Population值，第二列为Profit值。

使用`insert()`函数为population'列前添加值均为1的一列，方便矩阵运算，将前两列作为训练值X，后一列作为目标Y

```py
data.insert(0, 'Ones', 1)

# set X (training data) and y (target variable)
# data.shape 得到一个一维数组数组，data.shape[0]、data.shape[1]分别存储列数、行数
cols = data.shape[1]

# data.iloc[row_index,col_index[，选择所有数据，数据范围是[row_index,col_index]
X = data.iloc[:, 0:cols - 1]  # X是所有行，去掉最后一列
y = data.iloc[:, cols - 1:cols]  # y是所有行，最后一列
```

得到向量：

```py
X = np.matrix(X.values)
y = np.matrix(y.values)
# theta 存储参数，一个(1,2)的矩阵，初始值设定为0，即：w = 0, b = 0
theta = np.matrix(np.array([0, 0]))
```

### 代价函数

![image-20230919001521478](https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230919001521478.png)

```py
# 代价函数
# X 输入数据，是一个(97,2)的矩阵，第一列为ones均为1，第二列为population为输入值
# y 输出数据，是一个(97,1)的矩阵
# theta 存储参数，一个(1,2)的矩阵，初始值设定为0，即：w = 0, b = 0
def computeCost(X, y, theta):
    # np.power，对于矩阵每一个项执行次方运算
    # X * theta.T ：theta.T为参数矩阵的转至，得到 y = wx + b，得到的是f(x)的(97,1)矩阵
    inner = np.power(((X * theta.T) - y), 2)
    # np.sun 矩阵求和
    return np.sum(inner) / (2 * len(X))
```

### 梯度下降算法

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230914125514822.png" alt="image-20230914125514822" style="zoom:67%;" />

```py
# 梯度下降算法
# alpha 学习率
# iters 学习次数
def gradientDescent(X, y, theta, alpha, iters):
    # 创建一个全0的（1,2）矩阵，临时存储theta改变后的值
    temp = np.matrix(np.zeros(theta.shape))
    # 参数个数，即2，theta.ravel()向量展平为一维，会改变原数据，而flatten不会改变原数据
    parameters = int(theta.ravel().shape[1])
    # 记录每一次学习的代价
    cost = np.zeros(iters)

    # 遍历每一次学习次数
    for i in range(iters):
        # X * theta.T ：theta.T为参数矩阵的转至，得到 y = wx + b，得到的是f(x)的(97,1)矩阵
        error = (X * theta.T) - y

        # 修改每一个参数j = 0时，修改 w，w = a/m * np.sum(np.multiply(error, X[:, j])
        # 修改 b = a/m * np.sum(error);
        for j in range(parameters):
            # X[:, j] 是一个(97, 1)矩阵，如果j = 0, 则X[:, j] 矩阵全为 1 ，此时term = error，计算w
            # 如果j = 1，X[:, j]为Population那一列，此时term = error * x，计算b
            term = np.multiply(error, X[:, j])
            temp[0, j] = theta[0, j] - ((alpha / len(X)) * np.sum(term))

        # 修改完之后theta赋值
        theta = temp
        # 计算代价并保存（用于画图）
        cost[i] = computeCost(X, y, theta)

    return theta, cost
```

### 函数调用

```py
alpha = 0.01
iters = 10000

g, cost = gradientDescent(X, y, theta, alpha, iters)
```

### 绘图

```py
# 创建等差数组，Population最小值到最大值，数组长度为100
x = np.linspace(data.Population.min(), data.Population.max(), 100)
f = g[0, 0] + (g[0, 1] * x)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 8))

# 画线
ax1.plot(x, f, 'r', label='Prediction')
# 画点
ax1.scatter(data.Population, data.Profit, label='Traning Data')
ax1.legend(loc=2)
ax1.set_xlabel('Population')
ax1.set_ylabel('Profit')
ax1.set_title('Predicted Profit vs. Population Size')

ax2.plot(np.arange(iters), cost, linewidth=2, color='red')
ax2.set_xlabel('Iterations')
ax2.set_ylabel('Cost')
ax2.set_title('Error vs. Training Epoch')
plt.show()
```

# 三、多变量线性回归(Linear Regression with Multiple Variables)

## 3.1 多维特征

目前为止，我们探讨了单变量/特征的回归模型，现在我们对房价模型增加更多的特征，例如房间数楼层等，构成一个含有多个变量的模型，模型中的特征为$(x_1,x_2,x_3,x_4)$。

![image-20230917150441348](https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230917150441348.png)

- $n$代表特征的数量
- $x^{(i)}$代表第 个训练实例，是特征矩阵中的第行，是一个**向量**（**vector**）。

例如上图的$x^{(2)} = 
 \begin{bmatrix}
 1416\\
 3\\
 2\\
40\\
\end{bmatrix}$

- $x^{(i)}_j$代表特征矩阵中第$i$行的第$j$个特征，也就是第$i$个训练实例的第$j$个特征。

因此多变量线性回归模型可以写作下面的形式：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230917151323629.png" alt="image-20230917151323629" style="zoom: 50%;" />

不妨定义$X=  
 \begin{bmatrix}
 x_1\\
 x_2\\
 x_3\\
x_4\\
\end{bmatrix}$，$W= \begin{bmatrix}
 w_1\\
 w_2\\
 w_3\\
w_4\\
\end{bmatrix}$，因此$f_{w,b}=W \cdot X + b$，$W^T$代表$W$矩阵的转置。

> 注意：这里的$W^T \cdot X$ 是点乘运算而不是矩阵乘法，因为向量是一维矩阵，使用`numpy.dot()`既可以实现点乘，也可以实现矩阵乘法。

## 3.2 多变量梯度下降

与单变量线性回归类似，在多变量线性回归中，我们也构建一个代价函数，则这个代价函数是所有建模误差的平方和，即：

$J（w_1,w_2,....,w_n)=\frac{1}{2m}\sum_{i=1}^m(f_{w,b}(x^{(i)})-y^{(i)})$

我们的目标和单变量线性回归问题中一样，是要找出使得代价函数最小的一系列参数。 多变量线性回归的批量梯度下降算法为：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230917155037373.png" alt="image-20230917155037373" style="zoom:67%;" />

求导之后：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230917155510153.png" alt="image-20230917155510153" style="zoom: 50%;" />

## 3.3 特征缩放

在我们面对多维特征问题的时候，我们要保证这些特征都具有相近的尺度，这将帮助梯度下降算法更快地收敛。

以房价问题为例，假设我们使用两个特征，房屋的尺寸和房间的数量，尺寸的值为 0-2000平方英尺，而房间数量的值则是0-5，以两个参数分别为横纵坐标，绘制代价函数的等高线图能，看出图像会显得很扁，梯度下降算法需要非常多次的迭代才能收敛。

![image-20230917164105795](https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230917164105795.png)

可以看到，数据集分布图中，数据可能分布的范围是一个及其扁的矩形，而该模型的代价函数分布图也是一个椭圆，解决的方法是尝试将所有特征的尺度都尽量缩放到-1到1之间。

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/b8167ff0926046e112acf789dba98057.png" alt="img" style="zoom: 67%;" />

最简单的方法是令：$x_n=\frac{x_n-u_n}{\sigma_n}$，其中 $u_n$是平均值，是$\sigma_n$标准差。也就是将数据集化为（0,1）正态分布。

## 3.4 学习率的选择

梯度下降算法收敛所需要的迭代次数根据模型的不同而不同，我们不能提前预知，我们可以绘制迭代次数和代价函数的图表来观测算法在何时趋于收敛。

![img](https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/cd4e3df45c34f6a8e2bb7cd3a2849e6c.jpg)

也有一些自动测试是否收敛的方法，例如将代价函数的变化值与某个阀值（例如0.001）进行比较，但通常看上面这样的图表更好。

梯度下降算法的每次迭代受到学习率的影响，如果学习率过小，则达到收敛所需的迭代次数会非常高；如果学习率过大，每次迭代可能不会减小代价函数，可能会越过局部最小值导致无法收敛。

**通常可以考虑尝试些学习率：$α=0.01,0.03,0.1,0.3,1,3,1$**

##  3.5 特征工程与多项式回归

例如在房价预测问题中：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230918125259342.png" alt="image-20230918125259342" style="zoom:67%;" />

$x_1$代表房屋的宽度，$x_2$代表房屋的纵向深度，$x_3=x_1\cdot x_2$代表房屋的使用面积，那么能得到预测模型：

$  f_ {W,b}  (  \overrightarrow {x}  )=  w_ {1}   x_ {1}  +  w_ {3}   x_ {2} +  w_ {3}   x_ {3}  + b$

创建一个新的特征值$x_3$就是所谓的**特征工程**的案例，可以利用对问题的知识或者直觉来设计新的特征值，该特征值通常是通过转换货组合问题的原始特征值来使得学习算法能作出更为准确的预测。

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230918125831344.png" alt="image-20230918125831344" style="zoom:50%;" />

但有时线性回归问题不能解决我们遇到的问题，有时候需要使用曲线来适应我们的数据

例如二次方模型： $ f_ {W,b} $ (x)= $ w_ {1} $ x+ $ w_ {2} $ $ x^ {2} $ + $ w_ {3} $ $ x^ {3} $ +b

例如三次方模型： $ f_ {W,b} $ ( $ \overrightarrow {x} $ )= $ w_ {1} $ $ x_ {1} $ + $ w_ {3} $ $ x_ {2} $ + $ w_ {3} $ $ x_ {3} $ +b

或者是根 号模型： $ f_ {w,b} $ (x)= $ w_ {1} $  x+ $ w_ {2} $ $ \sqrt {x} $ + b

**通常我们需要先观察数据然后再决定准备尝试怎样的模型。**

# 四、逻辑回归(Logistic Regression)

##   4.1 分类问题

在监督学习中，分类问题预测的变量$y$是离散值，尝试预测的是结果是否属于某一个类（例如正确或错误）。

常见分类问题的例子有：判断一封电子邮件是否是垃圾邮件；判断一次金融交易是否是欺诈；之前我们也谈到了肿瘤分类问题的例子，区别一个肿瘤是恶性的还是良性的。

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230918134202567.png" alt="image-20230918134202567" style="zoom:50%;" />

如果有下列关于肿瘤大小与是否是恶性肿瘤的数据集，如果仍使用线性回归来预测就会得到下面的这个模型：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230918134439442.png" alt="image-20230918134439442" style="zoom:50%;" />

我们可以定义一个阈值（threshold）来判断肿瘤是否为恶性（图中为0.5），如果预测结果 $ \widehat {y} < 0.5$ 则被定义为良性肿瘤，否则为恶性，这个预测模型看似是可靠的。但是考虑这一种情况：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230918134821125.png" alt="image-20230918134821125" style="zoom: 50%;" />

如果数据集新加入数据使得预测模型 $ f_ {w,b} $$ (x)=wx+b$ 改变为绿色直线，那么此时原本数据集中应当被判定为恶性肿瘤的部分数据，会被新模型判定为良性，这显然是不合理的。

我们会学习**逻辑回归算法（Logistic Regression）**来进行对分类问题的预测，它的输出值永远在0到 1 之间。

## 4.2 逻辑回归

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230918154339069.png" alt="image-20230918154339069" style="zoom:67%;" />

逻辑回归模型（如右图所示），其函数式：**$g(z)=$ $ \frac {1}{1+e^ {-z}} $ $0<g(z)<1$**

对于逻辑回归模型可以理解为**$z = w \cdot x +b $** ，得到的$z$值带入到$g（z）$中：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230918155217610.png" alt="image-20230918155217610" style="zoom: 50%;" />

对于逻辑回归模型的理解：若 $ f_ {W,b}(x_i) $ $=0.7$ 则$x_i$这个样本下， $ f_ {w,b}(x)=P(y=1|\overrightarrow {x},\overrightarrow {w},b) =70 \% $ ，即样本是恶性肿瘤的概率为70%

## 4.3 决策边界

**决策边界（Decision Boundary）：指在分类问题中，用于划分不同类别的边界或界限。**决策边界可以是一个超平面、曲线或其他形状，它将特征空间分成不同的区域，每个区域对应于一个特定的类别。

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230918161425838.png" alt="image-20230918161425838" style="zoom:50%;" />

在上述逻辑回归模型中，如果 $ f_ {w,b} $ (x) $ \geqslant $ $0.5$，则预测的结果为真，此时$g(z)\geqslant0.5$ ，那么$z\geqslant0$，即： $ \overrightarrow {w} $ $ \cdot $ $ \overrightarrow {x} $ $+b $ $\geqslant$ $ 0$。

同理不难退出，若预测结果为假，即：$ \overrightarrow {w} $ $ \cdot $ $ \overrightarrow {x} $ $+ b $ < $ 0$

因此对于预测模型总的$z$，有$z=0$的函数称作为决策边界，决策边界将预测为0或1的两部分区域分割开。

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230918162002408.png" alt="image-20230918162002408" style="zoom:50%;" />

例如上述模型中，$z=w_1x_1+w_2x_2+b$，此时决策边界为$x_1+x_2=3$

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230918162106553.png" alt="image-20230918162106553" style="zoom: 50%;" />

而在该模型中，$z=w_1x_1^2+w_2x_2^2+b$，此时决策边界为$x_1^2+x_2^2=1$。

可以用非常复杂的模型来适应非常复杂形状的判定边界。

## 4.4 代价函数

对于线性回归模型，我们定义的代价函数是所有模型误差的平方和。理论上来说，我们也可以对逻辑回归模型沿用这个定义，但是问题在于，当我们将**$g(z)=$ $ \frac {1}{1+e^ {-z}} $ **带入到这样定义了的代价函数中时，我们得到的代价函数将是一个非凸函数（**non-convexfunction**）。

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230918164549078.png" alt="image-20230918164549078" style="zoom:50%;" />

这意味着我们的代价函数有许多局部最小值，这将影响梯度下降算法寻找全局最小值。

重新定义逻辑归回模型的**代价函数（cost function）**如下，其中$L(  f_ {w,b}  (  x^ {(i)}  ),  y^ {(i)} ) $ 称为**损失函数（loss function） **。

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230918165531144.png" alt="image-20230918165531144" style="zoom:67%;" />

对于$ f_ {w,b}(x^{(i)}) $ 函数，其取值范围为：$(0,1)$，因此可以画出$L(  f_ {w,b}  (  x^ {(i)}  ),  y^ {(i)} ) $分布图：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/8b97dcb78406bea24939d146292d4d1.jpg" alt="8b97dcb78406bea24939d146292d4d1" style="zoom: 33%;" />

下面分情况来讨论：

1. 当$y^{(i)}==1时$：如果预测结果$ f_ {w,b}(x^{(i)}) $ 值为 1 ，此时预测成功，此时代价值为0；若$ f_ {w,b}(x^{(i)}) $ 值为 0，与真实情况不相符，此时代价值接近于无穷大

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230918165138641.png" alt="image-20230918165138641" style="zoom: 50%;" />

2. 当$y^{(i)}==0时$：如果预测结果$ f_ {w,b}(x^{(i)}) $ 值为 0 ，此时预测成功，此时代价值为0；若$ f_ {w,b}(x^{(i)}) $ 值为 1，与真实情况不相符，此时代价值接近于无穷大

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230918165356945.png" alt="image-20230918165356945" style="zoom: 50%;" />

如果将代价函数从分段函数简化为一般函数，代价函数可以写作：

![image-20230918170400097](https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230918170400097.png)

## 4.5   实现梯度下降

![image-20230918182314392](https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230918182314392.png)

可以看出梯度下降的实现方法与线性回归预测相似，下面列举 $ \frac {\delta }{\delta w_j}  J(w,b)$的证明过程：

![a0517626b4c87344293e5905d44edfb](https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/a0517626b4c87344293e5905d44edfb.jpg)

> 注意：$\overrightarrow{w}\cdot\overrightarrow{x}$是向量乘法，而$ \frac {\delta }{\delta w_j} \overrightarrow{w} \cdot \overrightarrow{x} $ 实际上是：$ \frac {\delta }{\delta w_j} (w_1\cdot x_1+w_2\cdot x_2 + ...+w_j\cdot x_j+ ... + w_n\cdot x_n) $，算出来的结果应该是是$x_j$

## 4.6 实训：训练逻辑回归模型

首先是数据导入部分，这里使用`data[data['Admitted'].isin([1])]`按照`Admitted`值的结果（0或1）将数据划分为两部分，用于数据的展示：

```py
# 读取数据集
data = pd.read_csv('ex2data1.txt', header=None, names=['Exam 1', 'Exam 2', 'Admitted'])
data.insert(0, 'num', 1)

# 划分数据集
positive = data[data['Admitted'].isin([1])]
negative = data[data['Admitted'].isin([0])]

# 获取数据集的数量和参数个数
col = data.shape[0]
n = data.shape[1]
X = data.iloc[:, 0:n - 1]
Y = data.iloc[:, n - 1: n]

X = np.array(X.values)
Y = np.array(Y.values)
```

接着是参数的设置：

```py
# 初始化参数和设置学习率、迭代次数
theta = np.array([[0, 0, 0]])
alpha = 0.001
iters = 1000000
```

接着先定义sigmoid函数：

![image-20230921205956574](https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230921205956574.png)

```py
def sigmoid(z):
    return 1. / (1. + np.exp(-z))
```

定义代价函数：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230921211451539.png" alt="image-20230921211451539" style="zoom: 50%;" />

```py
# 定义代价函数
def costFunction(theta, X, y):
    # '@' 跟np.dot()类似，是对于np.array() 的矩阵乘法运算符
    first = np.multiply(-y, np.log(sigmoid(X @ theta.T)))
    second = np.multiply((1 - y), np.log(1 - sigmoid(X @ theta.T)))
    return np.sum(first - second) / (len(X))
```

定义梯度下降函数：

```py
# 定义梯度下降函数
def gradient(theta, X, y, alpha, iters):
    # 初始化代价数组
    cost = np.zeros(iters)
    # 参数数量，这里是 3
    parameters = int(theta.ravel().shape[0])
    # 创建全 0 的（3,1）矩阵存储theta改变后的值，另一种写法是：grad = np.zeros((parameters, 1))
    grad = np.zeros(parameters).reshape(1, -1)

    for i in range(iters):
        error = sigmoid(np.dot(X, theta.T)) - y
        cost[i] = costFunction(theta, X, y)
        for j in range(parameters):
            term = np.multiply(error, X[:, j].reshape(-1, 1))
            grad[0, j] = theta[0, j] - ((alpha / len(X)) * np.sum(term))
		
        theta = grad.copy()

    return grad, cost
```

绘图：

```py
# 绘制数据点和决策边界
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 8))
xx = np.linspace(data['Exam 1'].min(), data['Exam 1'].max(), 100)
yy = (-g[0, 0] - xx * g[0, 1])/ g[0, 2]
ax1.scatter(positive['Exam 1'], positive['Exam 2'], s=50, c='b', marker='o', label='Accepted')
ax1.scatter(negative['Exam 1'], negative['Exam 2'], s=50, c='r', marker='x', label='Rejected')
ax1.legend()
ax1.set_xlabel('Exam 1 Score')
ax1.set_ylabel('Exam 2 Score')
ax1.plot(xx, yy, 'r', label='Prediction')

# 绘制代价函数随迭代次数的变化
ax2.plot(np.arange(iters), cost, linewidth=2, color='red')
ax2.set_xlabel('Iterations')
ax2.set_ylabel('Cost')
ax2.set_title('Error vs. Training Epoch')
```

完整代码：

```py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# 定义 sigmoid 函数
def sigmoid(z):
    return 1. / (1. + np.exp(-z))

# 定义代价函数
def costFunction(theta, X, y):
    # '@' 跟np.dot()类似，是对于np.array() 的矩阵乘法运算符
    first = np.multiply(-y, np.log(sigmoid(X @ theta.T)))
    second = np.multiply((1 - y), np.log(1 - sigmoid(X @ theta.T)))
    return np.sum(first - second) / (len(X))

# 定义梯度下降函数
def gradient(theta, X, y, alpha, iters):
    # 初始化代价数组
    cost = np.zeros(iters)
    # 参数数量，这里是 3
    parameters = int(theta.ravel().shape[0])
    # 创建全 0 的（3,1）矩阵存储theta改变后的值，另一种写法是：grad = np.zeros((parameters, 1))
    grad = np.zeros(parameters).reshape(1, -1)

    for i in range(iters):
        error = sigmoid(np.dot(X, theta.T)) - y
        cost[i] = costFunction(theta, X, y)
        for j in range(parameters):
            term = np.multiply(error, X[:, j].reshape(-1, 1))
            grad[0, j] = theta[0, j] - ((alpha / len(X)) * np.sum(term))

        theta = grad.copy()

    return grad, cost

# 读取数据集
data = pd.read_csv('ex2data1.txt', header=None, names=['Exam 1', 'Exam 2', 'Admitted'])
data.insert(0, 'num', 1)

# 将数据集分为正例和负例
positive = data[data['Admitted'].isin([1])]
negative = data[data['Admitted'].isin([0])]

# 获取数据集的数量和参数个数
col = data.shape[0]
n = data.shape[1]
X = data.iloc[:, 0:n - 1]
Y = data.iloc[:, n - 1: n]

X = np.array(X.values)
Y = np.array(Y.values)

# 初始化参数和设置学习率、迭代次数
theta = np.array([[0, 0, 0]])
alpha = 0.001
iters = 50000000

# 调用梯度下降函数进行训练
g, cost = gradient(theta, X, Y, alpha, iters)

# 绘制数据点和决策边界
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 8))
xx = np.linspace(data['Exam 1'].min(), data['Exam 1'].max(), 100)
yy = (-g[0, 0] - xx * g[0, 1])/ g[0, 2]
ax1.scatter(positive['Exam 1'], positive['Exam 2'], s=50, c='b', marker='o', label='Accepted')
ax1.scatter(negative['Exam 1'], negative['Exam 2'], s=50, c='r', marker='x', label='Rejected')
ax1.legend()
ax1.set_xlabel('Exam 1 Score')
ax1.set_ylabel('Exam 2 Score')
ax1.plot(xx, yy, 'r', label='Prediction')

# 绘制代价函数随迭代次数的变化
ax2.plot(np.arange(iters), cost, linewidth=2, color='red')
ax2.set_xlabel('Iterations')
ax2.set_ylabel('Cost')
ax2.set_title('Error vs. Training Epoch')
plt.show()
```

结果：

![image-20230921213408516](https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230921213408516.png)

# 五、正则化

## 5.1 过拟合

过拟合的问题就是指我们有非常多的特征，通过学习得到的模型能够非常好地适应训练集（代价函数可能几乎为0），但是推广到新的数据集上效果会非常的差。
下面以回归问题举例：
![img](https://huatu.98youxi.com/markdown/work/uploads/upload_e532531612cd66a1cedf807816e0a047.png)



- 图一模型不适合数据集，无法正确模拟数据，这种情况称之为欠拟合（underfit）或是高偏差（high bias）
- 图二模型刚好合适，其泛化能力最好
- 图三模型参数过多，若使用图三模型进行预测偏差会很大，这种情况称之为过拟合（overfit）或是高方差（high variance）



过拟合的情况在分类问题中同样会出现，例如：



![img](https://huatu.98youxi.com/markdown/work/uploads/upload_4b812a8601a695601eec82efad26a053.png)

那么应该如何防止过拟合呢？下面给出三种方法：

1. 收集更多的数据。
2. 选择合适的特征。
3. 正则化。

## 5.2 正则化

**正则化（regularization）**的目标是保留尽可能多的特征值，但是每一个特征值对应的参数应当是最小的。

为了实现正则化，将参数的大小作为代价函数的考虑标准之一，因此代价函数改写为下面这种形式：

![img](https://cdn.nlark.com/yuque/0/2023/png/22608736/1695195791855-7ca7f7ad-c705-442f-b933-7af41c95012b.png)

-  ![img](https://cdn.nlark.com/yuque/__latex/4760e2f007e23d820825ba241c47ce3b.svg)代表训练集中样本数量
- ![img](https://cdn.nlark.com/yuque/__latex/e520c061a407db472027709bf3f73290.svg)表示参数代价率，这个值大于0
- ![img](https://cdn.nlark.com/yuque/__latex/df378375e7693bdcf9535661c023c02e.svg)代表参数![img](https://cdn.nlark.com/yuque/__latex/e962475aca62e7f210f40004870bd692.svg)的数量（一般不考虑 ![img](https://cdn.nlark.com/yuque/__latex/d29c2e5f4926e5b0e9a95305650f6e54.svg))

加号左侧为原来的平方差代价，加号右侧为正则化代价值。

对于![img](https://cdn.nlark.com/yuque/__latex/e520c061a407db472027709bf3f73290.svg)值的选择需要额外留意，如果该值选择过大，学习后各参数参数![img](https://cdn.nlark.com/yuque/__latex/e962475aca62e7f210f40004870bd692.svg)都会是很小的值（假想为0），那么此时模拟出来的模型会是一条直线，此时模型欠拟合；如果该值选择过小（假想为0），那么此时正则化代价值可以忽略不计，此时模型过拟合。

## 5.3 线性回归正则化

线性回归正则化代价方程：

![img](https://cdn.nlark.com/yuque/0/2023/png/22608736/1695196358134-98dc155a-70bb-42b6-894c-82abb48eb57b.png)

梯度下降算法：

![img](https://cdn.nlark.com/yuque/0/2023/png/22608736/1695196420033-7387035d-d414-4bff-b425-436f39e3e521.png)

将![img](https://cdn.nlark.com/yuque/__latex/e962475aca62e7f210f40004870bd692.svg)项合并在一起：![img](https://cdn.nlark.com/yuque/0/2023/png/22608736/1695196766347-7d67d41e-5bda-45b3-a17f-6569bf08c5d9.png)不难发现正则化是通过 ![img](https://cdn.nlark.com/yuque/__latex/71db9fea61ad1556f373b3454b69bc82.svg) 来一步一步缩小![img](https://cdn.nlark.com/yuque/__latex/e962475aca62e7f210f40004870bd692.svg)的值。

## 5.4 逻辑回归正则化

跟线性回归的类似，直接贴图：

![img](https://cdn.nlark.com/yuque/0/2023/png/22608736/1695197220236-17abec5c-989b-49dd-b929-5bc9a3d0bce1.png)

## 5.5 实训：训练逻辑回归正则化模型

**介绍**

此次实训的目标是搭建一个 $x_1,x_2$ 的多项式模型来进行逻辑回归预测，为了防止训练后的模型出现过拟合情况需要加入正则化约束是的参数的权重都尽可能的小。下面是部分数据以及数据的分布图：



![image-20230922213307303](https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230922213307303.png)<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230922213332681.png" alt="image-20230922213332681" style="zoom: 80%;" />

**读取数据**

首先是数据导入部分，跟之前一样，这里使用`data[data['Admitted'].isin([1])]`按照`Admitted`值的结果（0或1）将数据划分为两部分，用于数据的展示：

```py
# 读取数据集
data = pd.read_csv('ex2data1.txt', header=None, names=['Exam 1', 'Exam 2', 'Admitted'])
data.insert(3, 'Ones', 1)
# 划分数据集
positive = data[data['Admitted'].isin([1])]
negative = data[data['Admitted'].isin([0])]
```

**处理数据**

相较于线性逻辑回归，多项式逻辑回归中还需要 $x_1,x_2$ 其他次方来组成多项式模型，这里使用一个 $for$ 循环分别将$x_1^2x_2^0$、$x_1x_2$、$x_1^3x_2$ 等等参数也存如data中，处理完毕后data中的数据集：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230922215800827.png" alt="image-20230922215800827" style="zoom:50%;" />

```py
# 定义多项式分割次数
degree = 5
x1 = data['Exam 1']
x2 = data['Exam 2']

for i in range(1, degree):
    for j in range(0, i):
        data['F' + str(i) + str(j)] = np.power(x1, i - j) * np.power(x2, j)

data.drop('Exam 1', axis=1, inplace=True)
data.drop('Exam 2', axis=1, inplace=True)
```

**设置参数**

```py
# 初始化参数和设置学习率、迭代次数
theta = np.random.randn(1, X.shape[1])
alpha = 0.1
iters = 100000
# 学习率
learningRate = 1
```

**代价函数**

```py
# 定义代价函数
def costFunction(theta, X, y, learningRate):
    first = np.multiply(-y, np.log(sigmoid(X @ theta.T)))
    second = np.multiply((1 - y), np.log(1 - sigmoid(X @ theta.T)))
    reg = (learningRate / (2 * len(X)) * np.sum(np.power(theta[:, 1: theta.shape[1]], 2)))
    return np.sum(first - second) / (len(X)) + reg
```

**梯度下降函数**

```py
# 定义梯度下降函数
def gradient(theta, X, y, alpha, iters, learningRate):
    cost = np.zeros(iters)
    parameters = int(theta.ravel().shape[0])
    grad = np.zeros(parameters).reshape(1, -1)

    for i in range(iters):
        error = sigmoid(np.dot(X, theta.T)) - y
        cost[i] = costFunction(theta, X, y, learningRate)
        for j in range(parameters):
            term = np.multiply(error, X[:, j].reshape(-1, 1))
            if j == 0:
                grad[0, j] = theta[0, j] - (alpha / len(X)) * np.sum(term)
            else:
                grad[0, j] = theta[0, j] - (alpha / len(X)) * (np.sum(term) + (learningRate * theta[0, j]))
        theta = grad
     
	   # 绘制进度条
        progress = (i + 1) / iters
        bar_length = 30
        filled_length = int(bar_length * progress)
        bar = '#' * filled_length + '-' * (bar_length - filled_length)
        percentage = progress * 100
        print(f'Progress: [{bar}] {percentage:.1f}%', end='\r')

    return theta, cost
```

**计算 z 值的函数** 
$$
z=\overrightarrow x \cdot \overrightarrow w + b
$$


```py
def functionZ(degree, x1, x2, theta):
    sum = 0
    t = 1
    for i in range(1, degree):
        for j in range(0, i):
            sum += np.power(x1, i - j) * np.power(x2, j) * theta[0, t]
            t = t + 1
    return sum + theta[0, 0]
```

**计算预测准确性**

```py
def predict(theta, X):
    # 使用训练好的参数预测标签
    probability = sigmoid(X @ theta.T)
    predictions = (probability >= 0.5).astype(int)
    return predictions

# X : 输出多项式的多项式版训练集
def accuracy(theta, X, y):
    # 计算模型预测的准确度
    predictions = predict(theta, X)
    accuracy = np.mean(predictions == y) * 100
    return accuracy
```

**绘图**

```py
# 绘制判决边界
x1 = np.linspace(-1, 1, 1000)
x2 = np.linspace(-1, 1, 1000)

x1, x2 = np.meshgrid(x1, x2)
z = functionZ(degree, x1, x2, theta)

ax2.scatter(positive['Exam 1'], positive['Exam 2'], s=50, c='b', marker='o', label='Accepted')
ax2.scatter(negative['Exam 1'], negative['Exam 2'], s=50, c='r', marker='x', label='Rejected')
ax2.set_xlabel('Exam 1 Score')
ax2.set_ylabel('Exam 2 Score')
ax2.legend()
ax2.set_title('Decision Boundary')
ax2.contour(x1, x2, z, levels=[0], colors='r', linewidths=2)
plt.grid(True)
plt.show()
```

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230922224959197.png" alt="image-20230922224959197" style="zoom:80%;" />

# 六、神经网络

## 6.1 神经网络概述

我们之前学的，无论是线性回归还是逻辑回归都有这样一个缺点，即：当特征太多时，计算的负荷会非常大。

下面是一个例子：

![img](https://cdn.nlark.com/yuque/0/2023/png/22608736/1695199192883-60ff3080-5b5d-467a-94e9-d50d2a50c4d2.png)

 使用非线性的多项式项，能够帮助我们建立更好的分类模型。假设我们有非常多的特征，例如大于100个变量，我们希望用这100个特征来构建一个非线性的多项式模型，结果将是数量非常惊人的特征组合，即便我们只采用两两特征的组合，我们也会有接近5000个组合而成的特征。这对于一般的逻辑回归来说需要计算的特征太多了。

假设我们希望训练一个模型来识别视觉对象（例如识别一张图片上是否是一辆汽车），我们怎样才能这么做呢？一种方法是我们利用很多汽车的图片和很多非汽车的图片，然后利用这些图片上一个个像素的值（饱和度或亮度）来作为特征。

假如我们只选用灰度图片，每个像素则只有一个值（而非 **RGB**值），我们可以选取图片上的两个不同位置上的两个像素，然后训练一个逻辑回归算法利用这两个像素的值来判断图片上是否是汽车：

![img](https://cdn.nlark.com/yuque/0/2023/jpeg/22608736/1695199192947-afefd15d-9417-4853-ba5f-8d99d50cddf7.jpeg)

假使我们采用的都是50x50像素的小图片，并且我们将所有的像素视为特征，则会有 2500个特征，如果我们要进一步将两两特征组合构成一个多项式模型，则会有约个（接近3百万个）特征。普通的逻辑回归模型，不能有效地处理这么多的特征，这时候我们需要神经网络。

## 6.2 神经网络模型

为了构建神经网络模型，我们需要首先思考大脑中的神经网络是怎样的？每一个神经元都可以被认为是一个处理单元/神经核（**processing unit**/**Nucleus**），它含有许多输入/树突（**input**/**Dendrite**），并且有一个输出/轴突（**output**/**Axon**）。神经网络是大量神经元相互链接并通过电脉冲来交流的一个网络。

![img](https://cdn.nlark.com/yuque/0/2023/jpeg/22608736/1695199193534-a274e852-d3c6-4d25-99c8-7dc2fcf67320.jpeg)

这里是一条连接到输入神经，或者连接另一个神经元树突的神经，接下来这个神经元接收这条消息，做一些计算，它有可能会反过来将在轴突上的自己的消息传给其他神经元。这就是所有人类思考的模型：我们的神经元把自己的收到的消息进行计算，并向其他神经元传递消息。这也是我们的感觉和肌肉运转的原理。如果你想活动一块肌肉，就会触发一个神经元给你的肌肉发送脉冲，并引起你的肌肉收缩。如果一些感官：比如说眼睛想要给大脑传递一个消息，那么它就像这样发送电脉冲给大脑的。

![img](https://cdn.nlark.com/yuque/0/2023/png/22608736/1695200479707-f54df35c-8dbc-428b-b6b7-b3ed77e8488f.png)

神经网络模型建立在很多神经元之上，每一个神经元又是一个个学习模型。这些神经元（也叫激活单元，**activation unit**）采纳一些特征作为输出，并且根据本身的模型提供一个输出。下图是一个以逻辑回归模型作为自身学习模型的神经元示例，在神经网络中，参数又可被成为**权重（weight）。**

假设现在需要预测一件商品可能成为爆款的概率，现在有下面几个参数可能影响这个结果：价格（price）、运费（shipping cost）、营销（marketing）和材料（material）。进一步来看，价格+运费决定着用户支付能力（affordablity），营销决定着用户对该商品的注意力（awarness），价格+材料决定着用户对商品的感知质量（perceived quality），这三个属性无法通过数据输入得到，可以通过逻辑回归来预测得到，因此设计三个模型分别预测这三个属性值，而这三个属性值最终可以预测商品成为爆款的概率，因此再设计一个逻辑回归模型输入这三个属性最终可以预测成为爆款的概率。对于这四个模型，可以假想为四个神经元，现在设计如下四个神经元的网络：

![img](https://cdn.nlark.com/yuque/0/2023/jpeg/22608736/1695200687656-2493faf3-cf78-47a1-8534-ff0b648fd4a4.jpeg)

图其中price，shipping cost，marketing，material 是输入单元（**input units**），将原始数据输入给它们。 第二列的神经元负责将数据进行处理，像这样在图中呈一列的神经元我们将其称为**层（layer）。s**第一层神经元将数据加工后呈递到下一层。 

神经网络模型是许多逻辑单元按照不同层级组织起来的网络，每一层的输出变量都是下一层的输入变量。第一层称为**输入层（Input Layer）**，最后一层称为**输出层（Output Layer）**，中间一层成为**隐藏层（Hidden Layers）**。

![img](https://cdn.nlark.com/yuque/0/2023/jpeg/22608736/1695201917567-00e4ae61-8e38-4b10-b393-a16b41e37faa.jpeg)

如果将输入的数据看作是向量![img](https://cdn.nlark.com/yuque/__latex/e21e357da42934f1faed97ecb3177abf.svg), 那么经过隐藏层可以得到新向量![img](https://cdn.nlark.com/yuque/__latex/88762fff7bbdbf0f40d91a9bbc32f529.svg), 最终将 ![img](https://cdn.nlark.com/yuque/__latex/bf98c0ddcbe9c1e535f767c78c3aa813.svg) 输入输出层即可以得到结果。

- 下面是关于 hidden layer 的一些举例：

![img](https://cdn.nlark.com/yuque/0/2023/png/22608736/1695202845284-822d6aac-c546-41d8-885c-c2bc878327a3.png)

## 6.3 神经网络中的网络层

下面是一个拥有一个输入层、隐藏层、输出层的四神经元神经网络，我们首先将目光聚焦于隐藏层 layer 1。

<img src="https://cdn.nlark.com/yuque/0/2023/png/22608736/1695204927972-234d7c9a-75f5-4e65-abae-40bc2f32ae5c.png" alt="img" style="zoom: 33%;" />

隐藏层由三个神经元组成，每个神经元拥有一个逻辑回归模型，其参数用![img](https://cdn.nlark.com/yuque/__latex/37b4939efafe547be7e9f9de39ae8d73.svg)来表示。这一层是位于神经网络的第![img](https://cdn.nlark.com/yuque/__latex/53072c2388d69edc65c2377681e4e87c.svg)层，为了表示参数所在的层数，参数均在右上角添加 	![img](https://cdn.nlark.com/yuque/__latex/fe177192a7eeec389edbe1751e2456a8.svg)来表示所在的层数，例如![img](https://cdn.nlark.com/yuque/__latex/b68d9b22f1906a8a81b778a431a1fd9f.svg)用来表示第一层第一个神经元参数。同样的用![img](https://cdn.nlark.com/yuque/__latex/c766cb01b70109c9ff44785950aa545c.svg)来表示第一层输出的向量。

同样的，接下来来看layer 2 输出层：



<img align='center' src="https://cdn.nlark.com/yuque/0/2023/png/22608736/1695205519085-b5c4975a-788e-4fa7-b70b-4085668905cc.png" alt="img" style="zoom:33%;" />

可以看到 layer 1 的输出向量![img](https://cdn.nlark.com/yuque/__latex/c766cb01b70109c9ff44785950aa545c.svg)成为了layer 2 的输入数据项，第二层只有一个神经元而其参数为：![img](https://cdn.nlark.com/yuque/__latex/6d8a24bafe580e24747476cd3c7e6846.svg)。

最终作为layer 2 的输出向量（只有一个数值）![img](https://cdn.nlark.com/yuque/__latex/fbe8698769e179db2f1ba55ba6410831.svg) 只需要判断该值是否大于$0.5$ 即可判断商品是否可能成为爆款。

不难总结出一般式：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230921111013311.png" alt="image-20230921111013311" style="zoom:50%;" />

$\overrightarrow a^{[l - 1]}$ 称为 $l$ 层的**激活因子(Activation value of layer $l$)** ，也就是说：$\overrightarrow a^{[l - 1]}$ 作为输入参数会被带入到 $l$ 层的模型中运算。因此输入层输入的数据可以看作是 $\overrightarrow a^{[0]}$ ，其作用于第一个隐藏层 $ layer1$。

在神经网络中，这种通过将输入数据从输入层传递到输出层，逐层计算和传递数据的过程称为**网络层的前向传播（Forward Propagation）**。在这个过程中，每一层的神经元接收上一层的输出，并将其作为输入进行计算，最终产生输出。

## 6.4 Tensorflow实现简单网络

训练模型时可以分为下面几步：

1. 制定模型函数，确保模型能够很好地切合训练集及其预测的目标。
2. 确定成本函数（lost function）和损失函数（cost function）
3. 梯度下降算法计算模型

这三步在Tensorflow中的对应图如下：

![img](https://cdn.nlark.com/yuque/0/2023/png/22608736/1695379474816-458ceff1-ded7-46b6-9637-a76803917b95.png)

**第一步：创建网络架构**

![img](https://cdn.nlark.com/yuque/0/2023/png/22608736/1695379610385-c6f2d3b5-9c05-4f62-82c9-d2d3e47045ca.png)

`Dense()`函数用于创建神经网络模型中的一层，`units = 25`表示这一层中拥有25个神经元，`activation = 'sigmoid'`表示激活函数使用 sigmoid 函数。

**第二步：损失和成本函数**

![img](https://cdn.nlark.com/yuque/0/2023/png/22608736/1695380049012-90289366-5cea-46e4-82c1-11fe3bbcb466.png)

`model.compile(loss = )` 输入属性loss的值可以制定不同的损失函数，`loss = BinaryCrossentropy()`指定为逻辑回归损失函数，`loss = MeanSquaredError())`指定为线性回归平方差损失函数。

**第三步：梯度下降**

![img](https://cdn.nlark.com/yuque/0/2023/png/22608736/1695380486452-396e9213-d788-4751-8f6e-ad38db4c9403.png)

使用函数`model.fit(X, y epochs =)`来执行梯度下降算法，tensorflow汇使用逆向传播的方式计算损失函数的偏导数，这些都会自动执行。

## 6.5 激活函数

`激活函数`：其实就是存在于单个神经元中的模型函数。	

### ReLU激活函数

先给出ReLU激活函数的定 义：$z=\overrightarrow x \cdot \overrightarrow w + b$, $g(z)=m a x(0,z)$ReLU函数与线性回归激活函数类似，不过当![img](https://cdn.nlark.com/yuque/__latex/9a52d72174477fe9d70a6a63ae6d674b.svg)时 ![img](https://cdn.nlark.com/yuque/__latex/12e61f8782c5975569c9f5024a29823a.svg)。ReLU函数通常用于处理参数值为正数的情况，就比如还是之前的模型：

<img src="https://cdn.nlark.com/yuque/0/2023/png/22608736/1695382208566-85c4efbf-3b83-49b4-aa4b-893ca710c04c.png" alt="img" style="zoom:50%;" />

这里的 ![img](https://cdn.nlark.com/yuque/__latex/26270d94a618e4499fd26e8ebca50e72.svg)代表用户的注意程度，之前我们使用的是 sigmoid 激活函数只能是 0 或 1，但是现实中的注意力程度应该是一个非负数（比如 0～100），而线性逻辑回归可能会输出负数不适合，因此可以使用![img](https://cdn.nlark.com/yuque/__latex/1259b5b91c07484913919fa6fa9ce998.svg)激活函数。

**下面👇是三种激活函数图像对比：**

<img src="https://cdn.nlark.com/yuque/0/2023/png/22608736/1695382417767-2ba2fdfb-c1f1-44f4-a2f5-ea6f569f706e.png" alt="img" style="zoom:50%;" />

### 如何选择激活函数

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230922203301087.png" alt="image-20230922203301087" style="zoom:67%;" />

以上述的模型为例，在上述模型中存在一个输入层、两个隐藏层和一个输出层，下面来分别讨论：

- **对于输出层的激活函数：**这取决于该神经网络的目标
  - 例如做一个二分类问题毫无疑问使用`sigmoid`激活函数（分类）
  - 如果做一个预测问题且预测值为正负值使用线性逻辑回归预测（预测明天股票的涨跌）
  - 如果预测的的值为非零数那么使用`ReLU`激活函数（预测房屋的价格）
- **对于隐藏层的激活函数：**通常使用`ReLU`激活函数，下面介绍原因
  1. `ReLU`相较于`sigmoid`激活函数，其运算速度更快。sigmoid函数需要取幂取反，而ReLU函数只需要计算一次最大值。
  2. `sigmoid`激活函数在$x -> {+-} \infty$  时会变得扁平，这会导致梯度下降地很慢。

**综合上述观点：隐藏层的激活函数通常选择`ReLU`，输出层的激活函数通常按需选择。**下面是模型的TensorFlow构造代码：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230922204654592.png" alt="image-20230922204654592" style="zoom:67%;" />

### 不连续地使用线性回归激活函数

定义一个网络使用了两个隐藏层神经元并且每一个神经元都是使用线性回归激活函数，如下图所示：

 <img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230922204853671.png" alt="image-20230922204853671" style="zoom:67%;" />

现在假定输入单元为：$x$，那么有：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230922205032188.png" alt="image-20230922205032188" style="zoom:67%;" />

可以看到最终输出结果$\overrightarrow a ^{[2]} = w\cdot x + b$ ，这与一层线性回归模型的网络输出结果一致，因此当连续地使用线性回归激活函数时，效果仅仅只有一层，无法处理复杂的问题。 

## 6.6 多分类问题

### 概述

很多情况下，我们希望机器能够学习从而进行两种类别以上的分类，例如手写数据集的识别要求机器能够识别 0 ~ 9 的数据，在多分类问题中，决策边界可能如下图所示：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230924102220905.png" alt="image-20230924102220905" style="zoom:67%;" />

### Softmax函数

`Softmax`是逻辑回归算法的一种推广，主要解决的就是多分类问题，下面先回顾下二分类分类问题：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230924104230133.png" alt="image-20230924104230133" style="zoom: 67%;" />

根据逻辑回归的`sigmoid`函数，我们不难得到取到该分类的概率$a_1$，那么没有取到该分类的概率就是$1-a_1$。

现在将分类的数量增加到 4 个 ，每一个分类的`sigmoid`函数可以定义为 $g(z_i) = g(\overrightarrow w_i \cdot \overrightarrow x + b_i)$，那么定义`Softmax`函数为如下形式：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230924104944469.png" alt="image-20230924104944469" style="zoom:67%;" />

按照 4 个分类的情况举例：

<img src="https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230924105014207.png" alt="image-20230924105014207" style="zoom: 50%;" />

> 讨论：
>
> 1. **<font color='cornflowerblue'>为什么Softmax函数中要使用指数函数？</font>**
>
>    答：主要原因是为了**引入非线性**，使得模型能够更好地捕捉类别之间的差异。指数函数具有快速增长的特性，它可以将输入的值映射到更大的范围，从而增强了差异性。另外，指数函数的性质也有助于**处理数值稳定性**的问题。在计算Softmax函数时，指数函数的使用可以防止数值溢出或下溢，因为指数函数的输出范围是正实数，可以有效地处理较大或较小的数值。
>
>    
>
> 2. <font color='cornflowerblue'>**Softmax函数中使用sigmoid函数得到的值还是取到该类别的概率吗？**</font>
>
>    在多分类问题中，Sigmoid函数通常不直接用于表示每个分类的概率，可以理解为该分类的权重值，而Softmax函数就是通过这个权重值得到该分类的概率。

Softmax 在神经网络作用于输出层，Softmax 输出层中神经单元的数量与需要识别的分类数量$n$相同。Softmax输出层会输出取得不同类别的概率，如下图所示：

![image-20230924113227329](https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230924113227329.png)

### Softmax改进实现

先看看下面这段代码：

![image-20230924120855354](https://typora-md-bucket.oss-cn-beijing.aliyuncs.com/image-20230924120855354.png)

为什么`(2/10000)`与`(1 + 1/10000) - (1 - 1/10000)` 的结果会不同？是因为在`(1 + 1/10000) - (1 - 1/10000)`计算机会会对 `(1 + 1/10000)` 与 `(1 - 1/10000)` 进行两次舍入操作，最后两式相减还会进行一次舍入。本来舍入操作就会产生误差，将误差带入式子后会产生更大的误差，**因此在计算中要减少中间变量的产生，直接计算能够减小误差。**

现在回到



















